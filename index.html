<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/disk.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mingyuj666.github.io/">Mingyu Jinüåü</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://mingyuj666.github.io/">Qinkai Yuüåü</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://luckfort.github.io/">Jingyuan Huangüåü</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://qcznlp.github.io/">Qingcheng Zengüåü</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://zhentingwang.github.io/">Zhenting Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://wenyueh.github.io/">Wenyue Hua</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hy-zhao23.github.io/">Haiyan Zhao</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://dongyuanjushi.github.io/">Kai Mei</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://computerscience.exeter.ac.uk/people/profile/index.php?username=ymm206">Yanda Meng</a><sup>5</sup>,</span>
            <span class="author-block">
              <a href="https://kaize0409.github.io/">Kaize Ding</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://yangfan.sites.wfu.edu/">Fan Yang</a><sup>6</sup>,</span>
            <span class="author-block">
              <a href="https://mengnandu.com/">Mengnan Du</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://yongfeng.me/">Yongfeng Zhang</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Rutgers University,</span>
            <span class="author-block"><sup>2</sup>University of Liverpool,</span>
            <span class="author-block"><sup>3</sup>Northwestern University,</span>
            <span class="author-block"><sup>4</sup>New Jersey Institute of Technology,</span>
            <span class="author-block"><sup>5</sup>University of Exeter,</span>
            <span class="author-block"><sup>6</sup>Wake Forest University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!--
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>-->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.07066"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--<span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Luckfort/CD"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!--<span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="main image">
  <style type="text/css">
    body{
      background: url("./static/images/Bg.png") no-repeat center center fixed;
                  -webkit-background-size: cover;
                  -o-background-size: cover;                
                  background-size: cover;
    }
  </style>

  <div class="image-body">
    <div align=center>
      <img src="./static/images/Figure1.png" alt="CD Introduction" style="width: 50%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            <span class="dnerf">Concept Depth</span> is used to analyze the comprehension ability of Large Language Models (LLM) and the difficulty of a concept's understanding. We use probing techniquesüîç on each layer's embedding to detect the layer accuracy, F1-score, and AUC of the classification task.
          </h2>
        </div>
      </div>
    </div>
  </div>

  <br /> <br />

  <div class="image-body">
    <div align=center>
      <img src="./static/images/Figure2.png" alt="CD Introduction" style="width: 50%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            The LLMs are trying to understand easy tasks and complex tasks. The more complex the task, the deeper layers an LLM needs to understand. The stronger the LLM is, the more complex the task level it can learn.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Large language models (LLMs) have shown remarkable performances across a wide range of tasks. However, the mechanisms by which these models encode tasks of varying complexities remain poorly understood. In this paper, we explore the hypothesis that LLMs process concepts of varying complexities in different layers, introducing the idea of "Concept Depth" to suggest that more complex concepts are typically acquired in deeper layers. </p>

          <p>Specifically, we categorize concepts based on their level of abstraction, defining them in the order of increasing complexity within factual, emotional, and inferential tasks. We conduct extensive probing experiments using layer-wise representations across various LLM families (Gemma, LLaMA, Qwen) on various datasets spanning the three domains of tasks. </p>
          
          <p>Our findings reveal that models could efficiently conduct probing for simpler tasks in shallow layers, and more complex tasks typically necessitate deeper layers for accurate understanding. Additionally, we examine how external factors, such as adding noise to the input and quantizing the model weights, might affect layer-wise representations. Our findings suggest that these factors can impede the development of a conceptual understanding of LLMs until deeper layers are explored. </p>
          
          <p>We hope that our proposed concept and experimental insights will enhance the understanding of the mechanisms underlying LLMs. Our codes are available at 
            <a href="https://github.com/Luckfort/CD">
              <span>https://github.com/Luckfort/CD</span>.
            </a>
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>


  <br /> <br />


  <!--Main Body-->

  <!-- Dataset Intro -->
    
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">üóÉÔ∏èDataset Information</h2>
      
      <div class="content has-text-justified">
        <p align="center">
          We use the following datasets in our experiments.
        </p>
        
        <h4 class="title is-4" align="center">üí°Fact</h4>
        <p align="center">We let LLM solve true-of-false problems, based on an objective factual basis.</p>
        <p align="center">üåÜ <b>Cities</b>: Consists of statements about the location of cities and their veracity labels (e.g., The city of Zagreb is in Japan, which is wrong).</p>
        <p align="center">üîé <b>Common-Claim</b>: A dataset of boolean statements, each labeled by two humans as common-knowledge-true, common-knowledge-false, or neither.</p>
        <p align="center">üí• <b>Counterfact</b>: Includes myriad counterfactuals that allows quantitative testing of specificity and generalization when learning a counterfactual.</p>
        
        <h4 class="title is-4" align="center">‚ù§Ô∏èEmotion</h4>
        <p align="center">Given a social media or movie review, have the LLM solve a dichotomous sentiment problem.</p>
        <p align="center">üí¢ <b>HateEval</b>: Has tweets which were annotated hierarchically.</p>
        <p align="center">üé¨ <b>STSA</b>: Includes movie reviews, wih positive and negative reviews, reflecting the writer's overall intention for this review. </p>
        <p align="center">üìΩÔ∏è <b>IMDb</b>: A benchmark dataset for binary sentiment classification. We use 2000 of these samples.</p>
        <p align="center">ü§≠ <b>Sarcasm</b>: A superior news headline dataset that tells if the headlines are sarcastic.</p>

        <h4 class="title is-4" align="center">üß†Reasoning</h4>
        <p align="center">Examing LLM's reasoning skills for bi-classification.</p>
        <p align="center">üóùÔ∏è <b>StrategyQA</b>: Contains questions across all knowledge domains to elicit creative and diverse yes/no questions that require implicit reasoning steps.</p>
        <p align="center">ü™ô <b>Coinflip</b>: Includes coin flipping queries, asking if a coin remains heads up after it is either flipped or left unflipped by individuals.</p>
      </div>
    </div>
  </div>
  <!--/ Dataset Intro -->


  <!-- Case Example -->
    
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">üëÄCase Examples</h2>
      
      <div class="content has-text-justified">
        <h4 class="title is-4" align="center">Fact: Cities</h4>

        <p>
          ‚úÖ Judge the statement is True or False.
          <font color="#0000FF">
            The city of Tokyo is in Japan.
          </font>
        </p>
        <p>
          ‚ùå Judge the statement is True or False.
          <font color="#0000FF">
            The city of Lodz is in the Dominican Republic.
          </font> 
        </p>

        <h4 class="title is-4" align="center">Emotional: HateEval</h4>

        <p>
          ‚úÖ
          <font color="#0000FF">
            Here it is not about Refugees or Illegal immigrants. It is about whether one has documents before 1971 or not. Now, it is difficult for slum people and beggars to show valid documents, except the name in voter list. 
          </font>
          According to the comment, tell whether they present hate speech or not.
        </p>
        <p>
          ‚ùå
          <font color="#0000FF">
           Labor migrants transfer almost $10 billion a year to Ukraine.
          </font> According to the comment, tell whether they present hate speech or not.
        </p>

        <h4 class="title is-4" align="center">Reasoning: Coin-Flip</h4>

        <p>
          ‚úÖ
          <font color="#0000FF">
            A coin is heads up. Whitney flips the coin. Erika does not flip the coin. Tj does not flip the coin. Benito flips the coin. Is the coin still heads up? Note that "flip" here means "reverse".
          </font>
          According to the flipping process above, determine if a coin remains heads up after it is either flipped or left unflipped by individuals. Therefore, the answer (Yes or No) is?
        </p>
        <p>
          ‚ùå
          <font color="#0000FF">
            A coin is heads up. Lucky does not flip the coin. Mireya flips the coin. Jj flips the coin. Kc flips the coin. Is the coin still heads up? Note that "flip" here means "reverse".
          </font>
          According to the flipping process above, determine if a coin remains heads up after it is either flipped or left unflipped by individuals. Therefore, the answer (Yes or No) is?
        </p>

        
      </div>
    </div>
  </div>
  <!--/ Case Example -->

  <!-- Anchor. -->
    
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">‚öìÔ∏èAnchoring Difficulties</h2>

      <div class="image-body">
        <div align=center>
          <img src="./static/images/Anchor.png" alt="CD Introduction" style="width: 30%;">
          <div class="columns is-centered has-text-centered">
            <div class="column is-three-fifths">
              <h2 class="subtitle has-text-centered">
                The dataset with the highest accuracy, <span class="dnerf">IMDb</span>, is deemed the easiest dataset to classify. Conversely, the dataset with the lowest accuracy, <span class="dnerf">Coin-Flip</span>, is considered the most difficult to classify.
              </h2>
            </div>
          </div>
          
        </div>
      </div>
      
      <div class="content has-text-justified">
        <p>
          To ascertain the learning difficulty of each dataset, we have utilized the 
          <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct">
            <span>LlaMA3-8B-Instruct</span>.
          </a>
          model. 
          Our approach involves testing each sample in the datasets as a binary classification problem via a prompting way. 
        </p>
        <p>
          The model generates a response for each sample, from which we infer a judgment, categorizing it as either "Yes" or "No". 
          By comparing these judgments with the actual labels, we compute the accuracy for each dataset.
        </p>
        
      </div>
    </div>
  </div>
  <!--/ Anchor. -->


  <!-- Experiment. -->
    
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">üìäExperiments</h2>

        <div class="image-body">
          <div align=center>
            <img src="./static/images/all.png" alt="CD Introduction" style="width: 70%;">
            <div class="columns is-centered has-text-centered">
              <div class="column is-three-fifths">
                <h2 class="subtitle has-text-centered">
                  Linear probing accuracy of Gemma-7B, LLaMA-7B, Qwen-7B on nine datasets.
                </h2>
              </div>
            </div>
          </div>
        </div>

  <br /> <br />
      
  <div class="image-body">
    <div align=center>
      <img src="./static/images/peak.png" alt="CD Introduction" style="width: 100%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            The peak accuracy of each dataset on Gemma, LLaMA, and Qwen represented by the percent depth proportion.
          </h2>
        </div>
      </div>
    </div>
  </div>

  <br /> <br />
      
  <div class="image-body">
    <div align=center>
      <img src="./static/images/converge.png" alt="CD Introduction" style="width: 100%;">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="subtitle has-text-centered">
            The converging point of each dataset on Gemma, LLaMA, and Qwen represented by the percent depth proportion.
          </h2>
        </div>
      </div>
    </div>
  </div>

  <br /> <br />
      
      <div class="content has-text-justified">
        <p>
          To ascertain the learning difficulty of each dataset, we have utilized the 
          <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct">
            <span>LlaMA3-8B-Instruct</span>.
          </a>
          model. 
          Our approach involves testing each sample in the datasets as a binary classification problem via a prompting way. 
        </p>
        <p>
          The model generates a response for each sample, from which we infer a judgment, categorizing it as either "Yes" or "No". 
          By comparing these judgments with the actual labels, we compute the accuracy for each dataset.
        </p>
        
      </div>
    </div>
  </div>
  <!--/ Experiment. -->
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{jin2024exploring,
  author    = {Jin, Mingyu and Yu, Qinkai and Huang, Jingyuan and Zeng, Qingcheng and Wang, Zhenting and Hua, Wenyue and Zhao, Haiyan and Mei, Kai and Meng, Yanda and Ding, Kaize and others},
  title     = {Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?},
  journal   = {arXiv preprint arXiv:2404.07066},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
